---
layout: post
date: 2024-11-01 15:59:00-0400
inline: true
related_posts: false
---

Our work on optimized inference for binary and ternary neural networks is now available on arXiv! This groundbreaking research achieves significant speedup improvements for quantized LLMs.